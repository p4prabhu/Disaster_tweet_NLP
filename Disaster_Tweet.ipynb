{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real or Not? NLP with Disaster Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict which Tweets are about real disasters and which ones are not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv(r'C:\\\\Users\\\\Prabhat Singh\\Desktop\\dataset\\kaggle7\\sample_submission.csv')\n",
    "train=pd.read_csv(r'C:\\\\Users\\\\Prabhat Singh\\Desktop\\dataset\\kaggle7\\train.csv')\n",
    "test=pd.read_csv(r'C:\\\\Users\\\\Prabhat Singh\\Desktop\\dataset\\kaggle7\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train: (7613, 5)\n",
      "shape of test: (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of train: {train.shape}\")\n",
    "print(f\"shape of test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x254d2f086a0>"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of non disaster and disaster tweet\n",
    "sns.countplot(train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing value in train \n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing value in test\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "col =[\"id\",\"text\",\"target\"]\n",
    "train =train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1= [\"id\",\"text\"]\n",
    "test = test[col1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train: (7613, 3)\n",
      "shape of test: (3263, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of train: {train.shape}\")\n",
    "print(f\"shape of test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_tweet = train[train[\"target\"] ==1][\"text\"]\n",
    "non_disaster_tweet = train[train[\"target\"] == 0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how disaster tweet looks\n",
    "disaster_tweet.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how non disaster tweet looks\n",
    "non_disaster_tweet.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def pre(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].apply(lambda x: pre(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: pre(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "train[\"text\"] =train[\"text\"].apply(lambda x: tokenizer.tokenize(x))\n",
    "test[\"text\"] =test[\"text\"].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[people, receive, wildfires, evacuation, order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   1  [our, deeds, are, the, reason, of, this, earth...       1\n",
       "1   4      [forest, fire, near, la, ronge, sask, canada]       1\n",
       "2   5  [all, residents, asked, to, shelter, in, place...       1\n",
       "3   6  [people, receive, wildfires, evacuation, order...       1\n",
       "4   7  [just, got, sent, this, photo, from, ruby, ala...       1"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stop words\n",
    "def stp(text):\n",
    "    words=[w for w in text if w not in stopwords.words(\"english\")]\n",
    "    return words\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x : stp(x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x : stp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize the word in text\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "wnl=WordNetLemmatizer()\n",
    "def lemma(text):\n",
    "    text = [wnl.lemmatize(word) for word in text]\n",
    "    return text\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: lemma(x))\n",
    "test[\"text\"]= test[\"text\"].apply(lambda x: lemma(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the data\n",
    "def com(text):\n",
    "    combined = \" \".join(text)\n",
    "    return combined\n",
    "train[\"text\"]= train[\"text\"].apply(lambda x: com(x))\n",
    "test[\"text\"]= test[\"text\"].apply(lambda x: com(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "coun_vect = CountVectorizer()\n",
    "train_vec = coun_vect.fit_transform(train[\"text\"])\n",
    "test_vec = coun_vect.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "train_tfidf = tfidf.fit_transform(train['text'])\n",
    "test_tfidf = tfidf.transform(test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.61886792, 0.53525913, 0.58340181, 0.53521127, 0.70007831])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Classifier\n",
    "clf = LogisticRegression(C=1.0)\n",
    "scores = model_selection.cross_val_score(clf, train_vec, train[\"target\"], cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_vec, train[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.58645096, 0.50965961, 0.54725473, 0.48190279, 0.66840731])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_tfidf = LogisticRegression(C=1.0)\n",
    "scores = model_selection.cross_val_score(clf_tfidf, train_tfidf, train[\"target\"], cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count vectorizer perform better than tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64633141, 0.61151079, 0.67889908, 0.64435798, 0.73369565])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naives Bayes Classifier\n",
    "clf_NB = MultinomialNB()\n",
    "scores = model_selection.cross_val_score(clf_NB, train_vec, train[\"target\"], cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB.fit(train_vec, train[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57703631, 0.58523726, 0.62104363, 0.60203139, 0.74344718])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB_TFIDF = MultinomialNB()\n",
    "scores = model_selection.cross_val_score(clf_NB_TFIDF, train_tfidf, train[\"target\"], cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB_TFIDF.fit(train_tfidf, train[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf perform better on naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4994709 , 0.3826087 , 0.47914818, 0.38275499, 0.53211009])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "clf_xgb = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "scores = model_selection.cross_val_score(clf_xgb, train_vec, train[\"target\"], cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50054645, 0.3870334 , 0.47670251, 0.38266385, 0.56759176])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "clf_xgb_TFIDF = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "scores = model_selection.cross_val_score(clf_xgb_TFIDF, train_tfidf, train[\"target\"], cv=5, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submitting a file\n",
    "sample[\"target\"] = clf_NB_TFIDF.predict(test_tfidf)\n",
    "sample.to_csv(\"sample.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
